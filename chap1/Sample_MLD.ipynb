{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of CMIP6 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter some warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import os\n",
    "os.environ['NUMPY_EXPERIMENTAL_ARRAY_FUNCTION'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xesmf as xe\n",
    "import xarray as xr\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'intake'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mintake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_catalog\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m col \u001b[38;5;241m=\u001b[39m open_catalog(url)\u001b[38;5;241m.\u001b[39mclimate\u001b[38;5;241m.\u001b[39mcmip6_gcs()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'intake'"
     ]
    }
   ],
   "source": [
    "from intake import open_catalog\n",
    "url = \"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\"\n",
    "col = open_catalog(url).climate.cmip6_gcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for fetching cmip6 data from google cloud\n",
    "def rename_coords(ds):\n",
    "    ds = ds.copy()\n",
    "    \"\"\"Rename all depth dim to `lev`\"\"\"\n",
    "    if \"olevel\" in ds.coords:\n",
    "        ds = ds.rename({\"olevel\": \"lev\"})\n",
    "    if \"lev_partial\" in ds.coords:\n",
    "        ds = ds.rename({\"lev_partial\": \"lev\"})\n",
    "    \"\"\"Rename all latitude, longitude dim to `lat`,`lon`\"\"\"\n",
    "    if 'latitude' in ds.coords:\n",
    "        ds = ds.rename({'longitude': 'lon', 'latitude': 'lat'})\n",
    "    if 'nav_lat' in ds.coords:\n",
    "        ds = ds.rename({'nav_lon': 'lon', 'nav_lat': 'lat'})\n",
    "    return ds\n",
    "\n",
    "def get_dataset(col, var, freq, expe, model, grid):\n",
    "    dataset = col.search(variable_id = var, table_id = freq, experiment_id = expe, \n",
    "                         source_id = model, grid_label = grid).to_dataset_dict(\n",
    "        zarr_kwargs= {'consolidated': True, 'decode_times':True}, preprocess = rename_coords)\n",
    "    dataset = dataset[list(dataset)[0]].squeeze('member_id').reset_coords('member_id', drop = True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using here is from model GFDL-CM4's piControl data. We are using monthly ocean data and the variables we are looking for is 'so' sanility and 'thetao' temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'GFDL-CM4' \n",
    "experiment = 'piControl'\n",
    "frequency = 'Omon'\n",
    "variables = ['so', 'thetao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    }
   ],
   "source": [
    "# 'gr' is the regrided data (with one-dimentional lon & lat)\n",
    "dataset_gr = get_dataset(col, variables, frequency, experiment, model_name, 'gr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MLD\n",
    "We want to calculate the mid layer depth (MLD) from the temperature and sanility we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating potential density of selected year & month from temp & sanility.\n",
    "# def sel_time(ds, start_year, end_year, month = None):\n",
    "#     ds = ds.isel(time = slice((start_year-1)*12, end_year*12))\n",
    "#     if month:\n",
    "#         ds = list(ds.groupby(\"time.month\"))[month-1][-1]\n",
    "#     return ds\n",
    "\n",
    "def smow(t):\n",
    "    a = (999.842594, 6.793952e-2, -9.095290e-3, 1.001685e-4, -1.120083e-6,\n",
    "         6.536332e-9)\n",
    "    T68 = t * 1.00024\n",
    "    return (a[0] + (a[1] + (a[2] + (a[3] + (a[4] + a[5] * T68) * T68) * T68) *\n",
    "            T68) * T68)\n",
    "\n",
    "def dens0(s, t):\n",
    "    T68 = t * 1.00024\n",
    "    b = (8.24493e-1, -4.0899e-3, 7.6438e-5, -8.2467e-7, 5.3875e-9)\n",
    "    c = (-5.72466e-3, 1.0227e-4, -1.6546e-6)\n",
    "    d = 4.8314e-4\n",
    "    return (smow(t) + (b[0] + (b[1] + (b[2] + (b[3] + b[4] * T68) * T68) *\n",
    "            T68) * T68) * s + (c[0] + (c[1] + c[2] * T68) * T68) * s *\n",
    "            s ** 0.5 + d * s ** 2)\n",
    "\n",
    "# def func_dens0(dataset, start_year, end_year, month_no = 9): #\n",
    "#     da_t = sel_time(dataset.thetao, start_year, end_year, month = month_no)\n",
    "#     da_s = sel_time(dataset.so, start_year, end_year, month = month_no)\n",
    "#     da_dens = dens0(da_s, da_t)\n",
    "#     return da_dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_den = dens0(da_s, da_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating MLD\n",
    "# def func_mld(dens_diff, depths):\n",
    "#     '''\n",
    "#     Function for calculate mld from density difference (den - den10 - 0.03) and depth\n",
    "#     Return mixed layer depth \n",
    "#     '''\n",
    "#     if np.isnan(dens_diff[0]):\n",
    "#         mld = np.nan\n",
    "#     elif dens_diff[0] >= 0:\n",
    "#         mld = np.nan\n",
    "#     else:\n",
    "#         nthr_index = np.where(dens_diff > 0)[0]\n",
    "#         if len(nthr_index) == 0:\n",
    "#             naninds = np.where(np.isnan(dens_diff))[0]\n",
    "#             if len(naninds) > 0:\n",
    "#                 nanindex = naninds[0]\n",
    "#             else:\n",
    "#                 nanindex = len(depths)\n",
    "#             mld = depths[nanindex-1]\n",
    "#         else:\n",
    "#             nind = nthr_index[0] + 1\n",
    "#             mld = np.interp(0, dens_diff[:nind], depths[:nind])\n",
    "#     return mld\n",
    "\n",
    "def func_mld(dens_diff, depths):\n",
    "    '''\n",
    "    Function for calculate mld from density difference (den - den10 - 0.03) and depth\n",
    "    Return mixed layer depth \n",
    "    '''\n",
    "    if np.isnan(dens_diff[0]):\n",
    "        mld = np.nan\n",
    "    elif dens_diff[0] >= 0:\n",
    "        mld = np.nan\n",
    "    else:\n",
    "        nthr_index = np.where(dens_diff > 0)[0]\n",
    "        if len(nthr_index) == 0:\n",
    "            naninds = np.where(np.isnan(dens_diff))[0]\n",
    "            if len(naninds) > 0:\n",
    "                nanindex = naninds[0]\n",
    "            else:\n",
    "                nanindex = len(depths)\n",
    "            mld = depths[nanindex-1]\n",
    "        else:\n",
    "            nind = nthr_index[0] + 1\n",
    "            mld = np.interp(0, dens_diff[nind-2:nind], depths[nind-2:nind])                \n",
    "    return mld\n",
    "\n",
    "# def xr_func_mld(dens):\n",
    "#     '''\n",
    "#     Function for parallel computing\n",
    "#     '''\n",
    "#     dens10 = dens.interp(lev = 10, method = 'linear')  # density at 10m\n",
    "#     dens_diff = dens - dens10 - 0.03               # density differences \n",
    "#     mld = xr.apply_ufunc(\n",
    "#         func_mld, \n",
    "#         dens_diff.chunk({\"time\":25, \"lat\":45, \"lon\":45}),  \n",
    "#         dens_diff.lev, \n",
    "#         input_core_dims = [[\"lev\"], [\"lev\"]], \n",
    "#         vectorize = True,\n",
    "#         dask = \"parallelized\",\n",
    "#         output_dtypes = [dens_diff.lev.dtype])\n",
    "#     return mld\n",
    "\n",
    "def xr_func_mld(dens):\n",
    "    '''\n",
    "    Function for parallel computing\n",
    "    '''\n",
    "    dens10 = dens.interp(lev = 10, method = 'linear')  # density at 10m\n",
    "    dens_diff = dens - dens10 - 0.03               # density differences \n",
    "    mld = xr.apply_ufunc(\n",
    "        func_mld, \n",
    "        dens_diff,#.chunk({\"time\":25, \"x\":30, \"y\":30}),  \n",
    "        dens_diff.lev, \n",
    "        input_core_dims = [[\"lev\"], [\"lev\"]], \n",
    "        vectorize = True,\n",
    "        dask = \"parallelized\",\n",
    "        output_dtypes = [dens_diff.lev.dtype],\n",
    "    )\n",
    "    return mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1\n",
    "end_year = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mld = xr_func_mld(func_dens0(dataset_gr, start_year, end_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    memory = '8G',\n",
    "    processes = 1,\n",
    "    cores = 2, \n",
    "    nanny = True, \n",
    "    silence_logs = 'error')\n",
    "\n",
    "cluster.scale(32)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "Here, we want to plot the average mld over the selected years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "sep_mld_avg = sep_mld.mean(dim = 'time')\n",
    "sep_mld_avg = sep_mld_avg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.colors as colors\n",
    "from cartopy.util import add_cyclic_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_da = sep_mld_avg\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.set_extent([-180, 180, -90, -30], ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.LAND, zorder=1, color='0.8')\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=1.25)\n",
    "\n",
    "gl = ax.gridlines(\n",
    "    xlocs = np.arange(-180,180,30), \n",
    "    ylocs = np.arange(-90,90,20),\n",
    "    draw_labels=True, y_inline=True)\n",
    "\n",
    "plt_mld, plt_lon = add_cyclic_point(plt_da, coord=plt_da.lon)\n",
    "my_level = np.linspace(0,750,50)\n",
    "im = ax.contourf(plt_lon, plt_da.lat, plt_mld, transform=ccrs.PlateCarree(), levels = my_level, cmap=plt.cm.jet)\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label('m', fontsize=18, rotation=0, horizontalalignment = 'left')\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "plt.title('Averaged MLD in Southern Ocean, year {}-{}, {}'.format(start_year, end_year, model_name), fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
